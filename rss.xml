<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0"><channel><title>Fun Stuffs</title><link>http://compmathvn.github.io/</link><description>Some fun stuffs in maths, computer science, computer vision, robotics, etc.</description><atom:link type="application/rss+xml" href="http://compmathvn.github.io/rss.xml" rel="self"></atom:link><language>en</language><lastBuildDate>Thu, 14 Jul 2016 09:22:42 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Papers of interests - CVPR 2016 (1)</title><link>http://compmathvn.github.io/posts/papers-of-interests-cvpr-2016-1/</link><dc:creator>Some guys</dc:creator><description>&lt;div&gt;&lt;h3&gt;&lt;strong&gt;MATCHING&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Harwood_FANNG_Fast_Approximate_CVPR_2016_paper.pdf"&gt;&lt;strong&gt;FANNG: Fast Approximate Nearest Neighbour Graphs&lt;/strong&gt;&lt;/a&gt; 
&lt;a href="http://compmathvn.github.io/posts/harwood16cvpr"&gt;[notes]&lt;/a&gt;&lt;br&gt;
Ben Harwood, Tom Drummond&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Stumm_Robust_Visual_Place_CVPR_2016_paper.pdf"&gt;&lt;strong&gt;Robust Visual Place Recognition With Graph Kernels&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
Elena Stumm, Christopher Mei, Simon Lacroix, Juan Nieto, Marco Hutter, Roland Siegwart&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Lotan_Needle-Match_Reliable_Patch_CVPR_2016_paper.pdf"&gt;&lt;strong&gt;Needle-Match: Reliable Patch Matching Under High Uncertainty&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
Or Lotan, Michal Irani&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Sattler_Large-Scale_Location_Recognition_CVPR_2016_paper.pdf"&gt;&lt;strong&gt;Large-Scale Location Recognition and the Geometric Burstiness Problem&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
Torsten Sattler, Michal Havlena, Konrad Schindler, Marc Pollefeys&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Wang_The_Global_Patch_CVPR_2016_paper.pdf"&gt;&lt;strong&gt;The Global Patch Collider&lt;/strong&gt;&lt;/a&gt;&lt;br&gt;
Shenlong Wang, Sean Ryan Fanello, Christoph Rhemann, Shahram Izadi, Pushmeet Kohli&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="http://compmathvn.github.io/posts/papers-of-interests-cvpr-2016-1/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>papers</category><category>vision</category><guid>http://compmathvn.github.io/posts/papers-of-interests-cvpr-2016-1/</guid><pubDate>Wed, 13 Jul 2016 20:32:42 GMT</pubDate></item><item><title>About the famous Bayes rule</title><link>http://compmathvn.github.io/posts/about-the-famous-bayes-rule/</link><dc:creator>Some guys</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;To warm up for future posts about Bayesian Statistics, let's review the famous Bayes formula and other basic concepts in probability.&lt;/p&gt;
&lt;p&gt;The Bayes formula is &lt;em&gt;beautiful&lt;/em&gt; in the truest sense of this word. This simple formula governs the entire Bayesian inference world, whenever we want to guess the value of an unknown term \(x\) given our knowledge about another known (already measured) term \(z\):&lt;/p&gt;
$$ p(x|z) = \frac{p(z|x)p(x)}{p(z)} $$&lt;p&gt;This simple Bayes rule can answer everything, from the simplest question like: "I see the grass is wet. Was it raining yesterday?", to the most complicated problem, such as: "She is smiling to me. Does she actually love me???" Of course, these are just silly motivation examples. Bayes rule is actually used in 99.999% applications we see today in Google search, cars, airplanes, sattelites, to Mars Rovers and Curiosity... Ok, I lied. I don't know the exact number. But anyway...&lt;/p&gt;
&lt;p&gt;However, there are actually a lot going on in that simple formula. Each term has a different name, although they all look like "propability density" functions \(p(\cdot)\):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the posterior probability \(p(x|z)\)&lt;/li&gt;
&lt;li&gt;the likelihood function \(p(z|x)\)&lt;/li&gt;
&lt;li&gt;the prior probability \(p(x)\)&lt;/li&gt;
&lt;li&gt;and the "partition function" or "normalization constant" \(p(z)\)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It took me quite a while to grab the meaning of those terms. Here are several questions I had in mind when I first try to understand them. If you think you can answer them, think twice! However, if you are among the normal 90% as I am, I bet there are some subtleties explained here that you will find interesting.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Why do we need to compute the full posterior density \(p(x|z)\)? We just need to infer the one best value of \(x\) to make decision, don't we? &lt;/li&gt;
&lt;li&gt;Why is \(p(z|x)\) called a "likelihood function"? Is it just a "conditional probability"? What is the difference between a "likelihood function" and a "conditional probability"?&lt;/li&gt;
&lt;li&gt;What is a &lt;em&gt;conditional probability&lt;/em&gt; anyway? If we think the conditional probability density function \(p(a|b)\) as a function of two variables \(a\) and \(b\), how is it different from the &lt;em&gt;joint density&lt;/em&gt; \(p(a,b)\), which is also a function of two variables? &lt;/li&gt;
&lt;li&gt;Is the prior \(p(x)\) important? Why can't we just assume it a uniform distribution every time?&lt;/li&gt;
&lt;li&gt;What does it mean to say that \(p(z)\) is a normalization constant? Is it not a density function?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point, I realize that each question is actually worth a post for itself. I told you, there are a lot going on. Stay tunned!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
</description><guid>http://compmathvn.github.io/posts/about-the-famous-bayes-rule/</guid><pubDate>Thu, 03 Mar 2016 04:00:00 GMT</pubDate></item><item><title>Blog instructions</title><link>http://compmathvn.github.io/posts/blog-instructions/</link><dc:creator>Some guys</dc:creator><description>&lt;div&gt;&lt;h2&gt;Set up&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Install &lt;a href="https://getnikola.com/"&gt;Nikola&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Install &lt;a href="https://desktop.github.com/"&gt;git&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Clone the blog repository and checkout the develop branch:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;    mkdir ~/git
    cd ~/git
    git clone https://github.com/compmathvn/compmathvn.github.io.git
    cd compmathvn.github.io
    git checkout develop
&lt;/pre&gt;


&lt;ul&gt;
&lt;li&gt;Create your own post:  &lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;    nikola new_post -f markdown
    &amp;lt;give it a title: "My first post"&amp;gt;
&lt;/pre&gt;


&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: use &lt;code&gt;nikola new_post --help&lt;/code&gt; for more options.&lt;br&gt;
&lt;strong&gt;Note&lt;/strong&gt;: for ipython, simply copying an ipynb to the &lt;code&gt;posts&lt;/code&gt; folder won't work. Need to use &lt;code&gt;nikola new_post -f ipynb&lt;/code&gt; to generate the file with appropriate metadata.
&lt;/p&gt;&lt;p&gt;&lt;a href="http://compmathvn.github.io/posts/blog-instructions/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><guid>http://compmathvn.github.io/posts/blog-instructions/</guid><pubDate>Mon, 22 Feb 2016 07:20:00 GMT</pubDate></item><item><title>First post</title><link>http://compmathvn.github.io/posts/first-post/</link><dc:creator>Some guys</dc:creator><description>&lt;div&gt;&lt;p&gt;Try &lt;strong&gt;markdown&lt;/strong&gt; &lt;a href="https://help.github.com/articles/basic-writing-and-formatting-syntax/"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Awesome! &lt;a href="https://getnikola.com/handbook.html#math"&gt;Math&lt;/a&gt; works too!! &lt;/p&gt;
&lt;p&gt;Euler’s formula: \(e^{ix} = \cos x + i\sin x\)&lt;/p&gt;&lt;/div&gt;</description><category>mathjax</category><guid>http://compmathvn.github.io/posts/first-post/</guid><pubDate>Mon, 22 Feb 2016 05:58:01 GMT</pubDate></item></channel></rss>